# Gemini Multimodal Playground

A web application that demonstrates the capabilities of Google's Gemini Pro Vision model for multimodal interactions. This playground allows users to experiment with image and text inputs to explore 
the model's understanding and response generation.

## Features

- Upload and process images with Gemini Pro Vision
- Interactive chat interface
- Real-time responses from the model
- Support for both image and text inputs
- Modern and intuitive user interface

## Prerequisites

- Python 3.8 or higher
- Google Cloud API credentials
- Node.js and npm (for frontend development)

## Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/gemini-multimodal-playground.git
cd gemini-multimodal-playground
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up your environment variables:
```bash
export GOOGLE_API_KEY=your_api_key_here
```

## Usage

1. Start the application:
```bash
python app.py
```

2. Open your browser and navigate to `http://localhost:5000`

3. Upload an image and start interacting with the Gemini Pro Vision model

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Google's Gemini Pro Vision model
- All contributors to this project
- The open-source community

## Contact

For any queries or suggestions, please open an issue in the GitHub repository.

